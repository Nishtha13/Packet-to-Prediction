# -*- coding: utf-8 -*-
"""With Scaling DiffData CampusDay2ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14FngYnJcXiK37zIUyQn9w01V4bexe8Io
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/DATASET2/CampDSday2.csv')
df

import pandas as pd

# Assuming your DataFrame is named "df"


# Sort the DataFrame by timestamp
df = df.sort_values('timestamp')

# Group the DataFrame by event subtype
grouped = df.groupby('event subtype')

# Create a new column to store the corr_diff values
df['corr_diff'] = pd.NaT

# Iterate over each group
for _, group in grouped:
    # Get the difference between the current timestamp and the previous timestamp
    diff = group['timestamp'].diff()
    diff.iloc[0] = 0


    # Update the corr_diff column with the computed differences
    df.loc[group.index, 'corr_diff'] = diff

# Print the updated DataFrame
df

df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')
df['timestamp'] = df['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')

df

import pandas as pd

# Assuming your DataFrame is named "df" and has the "timestamp" and "event subtype" columns

# Convert timestamp column to datetime if it's not already
df['timestamp'] = pd.to_datetime(df['timestamp'])

# Define the start and end timestamps for each hour interval
hour_intervals = [
    ("2022-07-27 19:38:10", "2022-07-27 20:38:09"),
    ("2022-07-27 20:38:10", "2022-07-27 21:38:09"),
    ("2022-07-27 21:38:10", "2022-07-27 22:38:09"),
    ("2022-07-27 22:38:10", "2022-07-27 23:38:09"),
    ("2022-07-27 23:38:10", "2022-07-28 00:38:09"),
    ("2022-07-28 00:38:10", "2022-07-28 01:38:09"),
    ("2022-07-28 01:38:10", "2022-07-28 02:38:09"),
    ("2022-07-28 02:38:10", "2022-07-28 03:08:10")
]

# Create an empty DataFrame to store the counts
counts_df = pd.DataFrame(columns=['hour', 'event_subtype', 'count'])

# Iterate over each hour interval
for start, end in hour_intervals:
    # Filter the DataFrame for the current hour interval
    hour_df = df[(df['timestamp'] >= start) & (df['timestamp'] <= end)]

    # Group the DataFrame by event subtype and calculate the count
    event_counts = hour_df['event subtype'].value_counts().reset_index()
    event_counts.columns = ['event_subtype', 'count']

    # Add the hour information to the event_counts DataFrame
    event_counts['hour'] = start

    # Append the counts to the counts_df DataFrame
    counts_df = counts_df.append(event_counts)

# Print the counts DataFrame
counts_df

new_df1 = df.copy()

new_df1['label'] = None

new_df1['label'] = 'Unknown'

awake_range_1 = pd.date_range("2022-07-27 19:38:10", "2022-07-27 20:38:09", freq='S')
sleep_range_1 = pd.date_range("2022-07-27 20:38:10", "2022-07-27 21:38:09", freq='S')
awake_range_2 = pd.date_range("2022-07-27 21:38:10", "2022-07-27 22:38:09", freq='S')
sleep_range_2 = pd.date_range("2022-07-27 22:38:10", "2022-07-27 23:38:09", freq='S')
awake_range_3 = pd.date_range("2022-07-27 23:38:10", "2022-07-28 00:38:09", freq='S')
sleep_range_3 = pd.date_range("2022-07-28 00:38:10", "2022-07-28 01:38:09", freq='S')
awake_range_4 = pd.date_range("2022-07-28 01:38:10", "2022-07-28 02:38:09", freq='S')
sleep_range_4 = pd.date_range("2022-07-28 02:38:10", "2022-07-28 03:08:10", freq='S')

new_df1.loc[new_df1['timestamp'].isin(awake_range_1), 'label'] = 'Sleep'
new_df1.loc[new_df1['timestamp'].isin(sleep_range_1), 'label'] = 'Awake'
new_df1.loc[new_df1['timestamp'].isin(awake_range_2), 'label'] = 'Sleep'
new_df1.loc[new_df1['timestamp'].isin(sleep_range_2), 'label'] = 'Awake'
new_df1.loc[new_df1['timestamp'].isin(awake_range_3), 'label'] = 'Sleep'
new_df1.loc[new_df1['timestamp'].isin(sleep_range_3), 'label'] = 'Awake'
new_df1.loc[new_df1['timestamp'].isin(awake_range_4), 'label'] = 'Sleep'
new_df1.loc[new_df1['timestamp'].isin(sleep_range_4), 'label'] = 'Awake'

new_df1

unique_labels = new_df1['label'].unique()
print(unique_labels)

new_df1['label_ml'] = new_df1['label'].map({'Sleep': 0, 'Awake': 1})
new_df1

# output_file = '/content/CampusNigh2.xlsx'

# new_df1.to_excel(output_file, index=False)

unique_labels = new_df1['label_ml'].value_counts()
print(unique_labels)

new_df1.corr(method="pearson")

X = new_df1.drop(['label_ml','timestamp','label','Source MAC address','RSSI'],axis=1)
Y = new_df1['label_ml']
# new_df1 = new_df1.drop(['timestamp','label','Source MAC address','RSSI'],axis=1)

# X

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30)
# from sklearn.preprocessing import MinMaxScaler
# scaler = MinMaxScaler()
# fd = scaler.fit_transform(X)
# fd = pd.DataFrame(fd)
# X_train = scaler.fit_transform(X_train)
# # Y_test = Y_train
# # X_test = X_train

from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from imblearn.pipeline import Pipeline
from  imblearn.over_sampling import SMOTE
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import  precision_recall_fscore_support
from sklearn.neighbors import KNeighborsClassifier
from keras import backend as K
from sklearn.model_selection import cross_val_score

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

# Split the features and target variables for training data
X_train = new_df1.drop(['label_ml','timestamp','label','Source MAC address','RSSI'], axis=1)  # Features
y_train = new_df1['label_ml']  # Target variable

X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)

from sklearn.model_selection import KFold
cv = KFold(n_splits=5, random_state=1, shuffle=True)

steps = [('over', SMOTE()), ('model', KNeighborsClassifier())]
pipeline = Pipeline(steps=steps)
pipeline.fit(X_train,y_train)

predict = pipeline.predict(X_test)
predict

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
classification_report_result = classification_report(Y_test,predict)
print(classification_report_result)

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

y_scores = pipeline.predict_proba(X_test)[:, 1]  # Assuming binary classification

fpr, tpr, thresholds = roc_curve(Y_test, y_scores)

roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

steps = [('model',  RandomForestClassifier())]
pipeline = Pipeline(steps=steps)
pipeline.fit(X_train,y_train)
# scores = cross_val_score(pipeline, X, Y, cv=10, scoring='accuracy')
# # print the mean and standard deviation of the scores
# print(f'Mean accuracy: {scores.mean():.3f}')

predict = pipeline.predict(X_test)
predict

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
classification_report_result = classification_report(Y_test,predict)
print(classification_report_result)

y_scores = pipeline.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(Y_test, y_scores)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

steps = [('over', SMOTE()), ('model', LogisticRegression())]
pipeline = Pipeline(steps=steps)
pipeline.fit(X_train,y_train)
# scores = cross_val_score(pipeline, X, Y, cv=10, scoring='accuracy')
# # print the mean and standard deviation of the scores
# print(f'Mean accuracy: {scores.mean():.3f}')

pred= pipeline.predict(X_test)
pred

classification_report_result = classification_report(Y_test,pred)
print(classification_report_result)

y_scores = pipeline.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(Y_test, y_scores)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

steps = [('over', SMOTE()), ('model', LinearSVC())]
pipeline = Pipeline(steps=steps)
pipeline.fit(X_train,y_train)
# scores = cross_val_score(pipeline, X, Y, cv=10, scoring='accuracy')
# # print the mean and standard deviation of the scores
# print(f'Mean accuracy: {scores.mean():.3f}')

predict = pipeline.predict(X_test)
predict

y_scores = pipeline.decision_function(X_test)
roc_auc = roc_auc_score(Y_test, y_scores)

fpr, tpr, thresholds = roc_curve(Y_test, y_scores)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

classification_report_result = classification_report(Y_test,predict)
print(classification_report_result)

steps = [('over', SMOTE()), ('model', GradientBoostingClassifier())]
pipeline = Pipeline(steps=steps)
pipeline.fit(X_train,y_train)
# scores = cross_val_score(pipeline, X, Y, cv=10, scoring='accuracy')
# # print the mean and standard deviation of the scores
# print(f'Mean accuracy: {scores.mean():.3f}')

prediction = pipeline.predict(X_test)
prediction

classification_report_result = classification_report(Y_test,prediction)
print(classification_report_result)

y_scores = pipeline.predict_proba(X_test)[:, 1]
roc_auc = roc_auc_score(Y_test, y_scores)

fpr, tpr, thresholds = roc_curve(Y_test, y_scores)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

from keras.models import Sequential
from keras.layers import Dense
import matplotlib.pyplot as plt

def recall_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

def precision_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

def f1_m(y_true, y_pred):
    precision = precision_m(y_true, y_pred)
    recall = recall_m(y_true, y_pred)
    return 2*((precision*recall)/(precision+recall+K.epsilon()))

X = new_df1[['event subtype', 'corr_diff']]
y = new_df1['label_ml']

X = np.array(X)
y = np.array(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

input_shape = (X_train.shape[1],)  # Remove the extra dimension

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

# Apply normalization
X_train = X_train / 255.0
X_test = X_test / 255.0

y_train = y_train.astype('int32')

model = Sequential()
model.add(Dense(64, activation='relu', input_shape=input_shape))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])

history = model.fit(X_train, y_train, validation_split=0.5, epochs=10)

loss, accuracy = model.evaluate(X_test, y_test, verbose=0)

print(history.history.keys())

y_pred = model.predict(X_test)
y_pred = (y_pred > 0.5)  # Convert probabilities to binary predictions

# Assuming your target variable Y_test is one-hot encoded, you can convert it back to single-column labels
# Y_test_labels = Y_test.argmax(axis=1)
# y_pred_labels = y_pred.argmax(axis=1)

# Generate the classification report
report = classification_report(y_test, y_pred)
print(report)

# summarize history for accuracy
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('Model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='lower right')
plt.show()

import tensorflow as tf
from tensorflow.keras import layers
from sklearn.metrics import accuracy_score

X = new_df1[['event subtype','corr_diff']]
y = new_df1['label_ml']

X = np.array(X)
y = np.array(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

input_shape = (X_train.shape[1], 1)  # Add an extra dimension for channels
X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))
X_train = X_train.astype('float32')
y_train = y_train.astype('int32')

X_train = X_train / 255.0
X_test = X_test / 255.0

model = tf.keras.Sequential([
    layers.Conv1D(32, 1, activation='relu', input_shape=input_shape),
    layers.MaxPooling1D(2),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.fit(X_train, y_train, epochs=10, batch_size=32)

X_test = X_test.astype('float32')
y_pred = model.predict(X_test)
y_pred = y_pred.astype('float32')

classes_x = np.argmax(y_pred, axis=1)
y_test = y_test.reshape(-1)
classes_x = classes_x.reshape(-1)

accuracy = accuracy_score(y_test, classes_x)
print("Accuracy:", accuracy)

report = classification_report(y_test, classes_x)
print(report)

from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import classification_report

X = new_df1[['event subtype', 'corr_diff']]
y = new_df1['label_ml']

X = np.array(X)
y = np.array(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

input_shape = (X_train.shape[1], 1)  # Add an extra dimension

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

# Apply normalization
X_train = X_train / 255.0
X_test = X_test / 255.0

y_train = y_train.astype('int32')

# Apply undersampling
undersampler = RandomUnderSampler(random_state=42)
X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)

# Reshape the data for the model
X_train_resampled = X_train_resampled.reshape((X_train_resampled.shape[0], X_train_resampled.shape[1], 1))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# Continue with model training using the resampled data
model = tf.keras.Sequential([
    layers.Conv1D(32, 1, activation='relu', input_shape=input_shape),
    layers.MaxPooling1D(2),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])

history = model.fit(X_train_resampled, y_train_resampled, validation_data=(X_test, y_test), epochs=10)

# Generate predictions
y_pred = model.predict(X_test)
y_pred_classes = np.round(y_pred)

class_counts = np.bincount(y_train_resampled)
print("Class_counts",class_counts)

# Classification report
target_names = ['Class 0', 'Class 1']
report = classification_report(y_test, y_pred_classes, target_names=target_names)
print(report)
